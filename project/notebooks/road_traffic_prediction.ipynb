{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":251680,"sourceType":"datasetVersion","datasetId":43428}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### import all the necessary libraries:","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pass the warnings:","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Read the dataset and store it into pandas dataframe:","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('dft-road-casualty-statistics-accident-2021.csv', low_memory=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis:","metadata":{}},{"cell_type":"markdown","source":"### Displayt the shape of the dataset:","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Display the data types of all columns in the data frame:","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Display the column names in the data frame:","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### display the general information about the dataset:","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Print the first 10 rows of the dataset:","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Convert date into pandas datetime object:","metadata":{}},{"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'],)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extract day, month and week some useful features from 'date' column:","metadata":{}},{"cell_type":"code","source":"df['day'] = df['date'].dt.day\ndf['month'] = df['date'].dt.month\ndf['week'] = df['date'].dt.isocalendar().week","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### accident_severity is out target variable, display the unique values in accident_severity column:\n\n### 1 = Satal, 2= Serious and 3 = Slight","metadata":{}},{"cell_type":"code","source":"df['accident_severity'].unique()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### display the value count for the accident_severity (target) variable:","metadata":{}},{"cell_type":"code","source":"df['accident_severity'].value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Univariate Analysis:\n\n### Distribution of original data by target (accident_severity):","metadata":{}},{"cell_type":"code","source":"ax = sns.countplot(x = df.accident_severity ,palette=\"Set2\")\nsns.set(font_scale=1)\nax.set_xlabel(' ')\nax.set_ylabel(' ')\nfig = plt.gcf()\nfig.set_size_inches(14,8)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(df.accident_severity)), (p.get_x()+ 0.3, p.get_height()+10000))\n\nplt.title('Distribution of  Targets variable',fontsize = 15)\nplt.xlabel('Accident Severity',fontsize = 15)\nplt.ylabel('Frequency [%]',fontsize = 15)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Number of casualties distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.distplot(df.number_of_casualties).set_xlim(0,20)\nplt.xlabel('number_of_casualties' ,fontsize = 15)\nplt.ylabel('Density',fontsize = 15)\nplt.show()\nprint('Min:',    df.number_of_casualties.min(), '\\n'\n      'Max:',    df.number_of_casualties.max(), '\\n'\n      'Median:', df.number_of_casualties.median())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribution of accidents over the day","metadata":{}},{"cell_type":"code","source":"time_x = pd.to_datetime(df['time'], format='%H:%M').dt.hour\nplt.figure(figsize=(16,8))\nax = time_x.value_counts().sort_index().plot(kind = 'area')\nax.set_xlabel('Hours of the day', fontsize = 15)\nax.set_ylabel('Count of Accidents', fontsize = 15)\nax.set_title('Distribution of accidents over the day', fontsize = 15)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Number of vehicles distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.distplot(df.number_of_vehicles).set_xlim(0,20)\nplt.xlabel('number_of_vehicles',fontsize = 15)\nplt.ylabel('Density',fontsize = 15)\nplt.show()\nprint('Min:',    df.number_of_vehicles.min(), '\\n'\n      'Max:',    df.number_of_vehicles.max(), '\\n'\n      'Median:', df.number_of_vehicles.median())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### A boxplot to show Distribution of Speed Limit:","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize = (16, 8))\nsns.boxplot(x=df[\"speed_limit\"])\nplt.title(\"Distribution of Speed Limit\",fontsize = 15)\nplt.xlabel(\"Speed Limit\",fontsize = 15)\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Bar chart of \"day_of_week\"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nsns.countplot(x=df[\"day_of_week\"])\nplt.title(\"Number of Accidents by Day of Week\",fontsize = 15)\nplt.xlabel(\"Day of Week\",fontsize = 15)\nplt.ylabel(\"Count\",fontsize = 15)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Multivariate Analysis:\n\n### Scatter plot of \"speed_limit\" vs \"number_of_casualties\"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nplt.scatter(x=df[\"speed_limit\"], y=df[\"number_of_casualties\"])\nplt.title(\"Speed Limit vs Number of Casualties\",fontsize = 15)\nplt.xlabel(\"Speed Limit\",fontsize = 15)\nplt.ylabel(\"Number of Casualties\",fontsize = 15)\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Box plot of \"speed_limit\" by \"weather_conditions\"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nsns.boxplot(x=df[\"weather_conditions\"], y=df[\"speed_limit\"])\nplt.title(\"Speed Limit by Weather Conditions\",fontsize = 15)\nplt.xlabel(\"Weather Conditions\",fontsize = 15)\nplt.ylabel(\"Speed Limit\",fontsize = 15)\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Drop the unnecessary columns:","metadata":{}},{"cell_type":"code","source":"df.drop(['accident_index', 'accident_reference', 'local_authority_ons_district', 'local_authority_highway','time', 'date', 'lsoa_of_accident_location','accident_year'], axis = 1, inplace = True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check are there any missing values in the data frame:","metadata":{}},{"cell_type":"code","source":"df.isnull().any()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Count the number of missing values in each column of the data frame:","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fill the missing values in location_easting_osgr, location_northing_osgr, longitude and latitude columns:","metadata":{}},{"cell_type":"code","source":"df['location_easting_osgr'] = df['location_easting_osgr'].fillna(df['location_easting_osgr'].mean())\ndf['location_northing_osgr'] = df['location_northing_osgr'].fillna(df['location_northing_osgr'].mean())\ndf['longitude'] = df['longitude'].fillna(df['longitude'].mode()[0])\ndf['latitude'] = df['latitude'].fillna(df['latitude'].mode()[0])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Convert (1 = Satal, 2= Serious and 3 = Slight) to binary values (0 = Slight, 1 =  Serious): \n### Now we have binary classification problem","metadata":{}},{"cell_type":"code","source":"df['accident_severity'] = df['accident_severity'].replace([2 , 1], 0)\ndf['accident_severity'] = df['accident_severity'].replace(3, 1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Value counts of the accident_severity again:","metadata":{}},{"cell_type":"code","source":"df['accident_severity'].value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribution of original data by targets\n","metadata":{}},{"cell_type":"code","source":"\nax = sns.countplot(x = df.accident_severity ,palette=\"Set2\")\nsns.set(font_scale=1)\nax.set_xlabel(' ')\nax.set_ylabel(' ')\nfig = plt.gcf()\nfig.set_size_inches(14,8)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(df.accident_severity)), (p.get_x()+ 0.3, p.get_height()+10000))\n\nplt.title('Distribution of  Targets variable',fontsize = 15)\nplt.xlabel('Accident Severity',fontsize = 15)\nplt.ylabel('Frequency [%]',fontsize = 15)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Store features into feature matrix X and target into vector y:","metadata":{}},{"cell_type":"code","source":"# Features\nX = df.loc[:,df.columns != 'accident_severity']\n#Target\ny = df['accident_severity']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Selection using SelectKbest method:\n\n### import SelectKBest and f_classif from sklear for feature seletion:","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initialized SelectKBest with f_classif test and k= 15","metadata":{}},{"cell_type":"code","source":"test = SelectKBest(score_func=f_classif, k=15)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fit the SelectKBest  model:","metadata":{}},{"cell_type":"code","source":"fit = test.fit(X, y)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Transform the features:","metadata":{}},{"cell_type":"code","source":"filtered_features= fit.transform(X)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Show the supporting variables given by SelectKBest (True/false):","metadata":{}},{"cell_type":"code","source":"test.get_support()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Display the scores of the features assigned by the SelectkBest:","metadata":{}},{"cell_type":"code","source":"test.scores_","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Find the Feature importance for each feature:","metadata":{}},{"cell_type":"code","source":"feat_importances = pd.Series(test.scores_, index=X.columns)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Display the feature importance using a bar chart","metadata":{}},{"cell_type":"code","source":"feat_importances.nlargest(15).plot(kind='barh',figsize = (16,8))\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Getting the column names:","metadata":{}},{"cell_type":"code","source":"column_names = X.columns[test.get_support()]\ncolumn_names","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Selecting the  relevant columns given by SelectKbest only: ","metadata":{}},{"cell_type":"code","source":"X_Selectkbest = X[column_names]\nX_Selectkbest.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the data set into training and Testing sets (training set 80%, Testing set 20%):","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_Selectkbest, y, test_size=0.20, random_state=0)  ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Use StandardScaler to scale the values of the dataset:","metadata":{}},{"cell_type":"code","source":"SC = StandardScaler()\nX_train_scaled = SC.fit_transform(X_train)\nX_test_scaled = SC.fit_transform(X_test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \tExperimental Design:\n\n### Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"#Initialize the LogisticRegression Model\nLg_classifier = LogisticRegression()\n# Train the model on training set\nLg_classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = Lg_classifier.predict(X_train_scaled)\n#he Accuracy score for Logistic Regresson on seen data :\nLg_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for Logistic Regresson on seen data : ', Lg_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = Lg_classifier.predict(X_test_scaled)\n#he Accuracy score for Logistic Regresson on unseen data :\nLg_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for Logistic Regresson on unseen data : ', Lg_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Decision Tree Classifier Model","metadata":{}},{"cell_type":"code","source":"#Initialize the DecisionTreeClassifier Model\nDt_classifier = DecisionTreeClassifier()\n# Train the model on training set\nDt_classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = Dt_classifier.predict(X_train_scaled)\n#he Accuracy score for decision tree on seen data :\nDt_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for decision tree on seen data : ', Dt_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = Dt_classifier.predict(X_test_scaled)\n#he Accuracy score for decision tree on unseen data :\nDt_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for decision tree on unseen data : ', Dt_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### RandomForest Classifier Model","metadata":{}},{"cell_type":"code","source":"#Initialize the RandomForestClassifier Model\nRf_Classifier = RandomForestClassifier(n_estimators = 100, )\n# Train the model on training set\nRf_Classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = Rf_Classifier.predict(X_train_scaled)\n#he Accuracy score for Random Forest on seen data :\nRf_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for Random Forest on seen data : ', Rf_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = Rf_Classifier.predict(X_test_scaled)\n#he Accuracy score for Random Forest on unseen data :\nRf_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for Random Forest on unseen data : ', Rf_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Gradient Boosting Classifier Model","metadata":{}},{"cell_type":"code","source":"#Initialize the GradientBoostingClassifier Model\nGb_Classifier = GradientBoostingClassifier()\n# Train the model on training set\nGb_Classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = Gb_Classifier.predict(X_train_scaled)\n#he Accuracy score for Gradient Boosting on seen data :\nGb_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for Gradient Boosting on seen data : ', Gb_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = Gb_Classifier.predict(X_test_scaled)\n#he Accuracy score for  Gradient Boosting on unseen data :\nGb_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for  Gradient Boosting on unseen data : ', Gb_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### XGB Classifier Model","metadata":{}},{"cell_type":"code","source":"#Initialize the XGBClassifier Model\nXGB_Classifier = XGBClassifier()\n# Train the model on training set\nXGB_Classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = XGB_Classifier.predict(X_train_scaled)\n#he Accuracy score for XGB_Classifier on seen data :\nXGB_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for XGB_Classifier on seen data : ', XGB_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = XGB_Classifier.predict(X_test_scaled)\n#he Accuracy score for  XGB_Classifier on unseen data :\nXGB_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for XGB_Classifier on unseen data : ', XGB_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KNeighbors Classifier Model","metadata":{}},{"cell_type":"code","source":"#Initialize the KNeighborsClassifier Model\nKNN_Classifier = KNeighborsClassifier()\n# Train the model on KNeighborsClassifier set\nKNN_Classifier.fit(X_train_scaled, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on seen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on seen data\ny_pred = KNN_Classifier.predict(X_train_scaled)\n#he Accuracy score for KNN classifier on seen data :\nKNN_score_seen = accuracy_score(y_train, y_pred)\nprint('The Accuracy score for KNN_Classifier on seen data : ', KNN_score_seen)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction and evaluation on unseen data:","metadata":{}},{"cell_type":"code","source":"# Make prediction on unseen data\ny_pred = KNN_Classifier.predict(X_test_scaled)\n#he Accuracy score for  KNN classifier on unseen data :\nKNN_score_unseen = accuracy_score(y_test, y_pred)\nprint('The Accuracy score for KNN_Classifier on unseen data : ', KNN_score_unseen)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create two lists of model name and respective Accuracies:","metadata":{}},{"cell_type":"code","source":"scores = pd.Series([Lg_score_unseen, Dt_score_unseen, Rf_score_unseen, Gb_score_unseen, XGB_score_unseen, KNN_score_unseen,  ])\nModel_Names = ['Logistic Regression','DecisionTree Classifier','RandomForest Classifier', 'GBR Classifier' ,'XGB Classifier' ,'KNN Classifier',]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Comparision of Models  in terms  evaluation metric (accuracy Score): ","metadata":{}},{"cell_type":"code","source":"ax = scores.plot(kind = 'barh',figsize=(15,9),color=['black','gray','green','brown','pink','blue','red'])\nax.set_title('Comparision of Models (Accuracy) unseen data',fontsize=15)\nax.set_xticks([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\nax.set_yticklabels(Model_Names,fontsize=15,)\nax.set_ylabel(\"Models\",fontsize=15)\nax.set_xlabel(\"Accuracy\",fontsize=15)\n[ax.text(v, i, '{:.2f}%'.format(100*v)) for i, v in enumerate(scores)];\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# \tEvaluation and further modelling improvements","metadata":{}},{"cell_type":"markdown","source":"### Hyper parameter Tuning for Highest performing Model (Logistic Regression)","metadata":{}},{"cell_type":"code","source":"# Create logistic regression object\nlr = LogisticRegression()\n\n# Set hyperparameters to tune\nhyperparameters = {\n    'penalty': ['l1', 'l2'],\n    'C': [0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear']\n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  Create GridSearchCV object and fit it on training data:","metadata":{}},{"cell_type":"code","source":"# Create GridSearchCV object\nclf = GridSearchCV(lr, hyperparameters, cv=5)\n\n# Fit GridSearchCV object to training data\nclf.fit(X_train_scaled, y_train)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Print best hyperparameters and best score","metadata":{}},{"cell_type":"code","source":"# Print best hyperparameters and best score\nprint('Best parameters:', clf.best_params_)\nprint('Best score:', clf.best_score_)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}